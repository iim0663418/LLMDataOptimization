{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP5bTMHcIouxbcUShiZ9rfS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iim0663418/LLMDataOptimization/blob/main/Pandoc_%E5%AF%A6%E7%8F%BE%E6%A0%BC%E5%BC%8F%E4%BF%9D%E7%95%99%E7%9A%84%E6%96%87%E6%AA%94%E8%BD%89%E6%8F%9B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pandoc 是一個通用的文檔轉換工具，可以在多種格式之間轉換文檔，如 DOCX、ODT、Markdown、HTML、LaTeX 等。它能夠保留文檔的格式，並提供多種輸出選項。\n",
        "這段程式碼只支援 DOCX、ODT 運用：\n",
        "1. 先將文檔轉換為 HTML 格式，保留格式信息。\n",
        "2. 然後使用自定義的解析器從 HTML 中提取所需的結構化數據，並進一步轉換為其他格式。</br>\n",
        "\n",
        "方法論轉換成純文字檔案的過程。\n",
        "\n",
        "同時加入將 json 轉換成語言模型友善的 .txt 方法，藉此保留原有的格式"
      ],
      "metadata": {
        "id": "WzwWdghumUNU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K67Teg75jYnl",
        "outputId": "bcaa963b-23c6-4ea6-be4a-6311d87db87e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libcmark-gfm-extensions0.29.0.gfm.3 libcmark-gfm0.29.0.gfm.3 pandoc-data\n",
            "Suggested packages:\n",
            "  texlive-latex-recommended texlive-xetex texlive-luatex pandoc-citeproc\n",
            "  texlive-latex-extra context wkhtmltopdf librsvg2-bin groff ghc nodejs php\n",
            "  python ruby libjs-mathjax libjs-katex citation-style-language-styles\n",
            "The following NEW packages will be installed:\n",
            "  libcmark-gfm-extensions0.29.0.gfm.3 libcmark-gfm0.29.0.gfm.3 pandoc\n",
            "  pandoc-data\n",
            "0 upgraded, 4 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 20.6 MB of archives.\n",
            "After this operation, 156 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcmark-gfm0.29.0.gfm.3 amd64 0.29.0.gfm.3-3 [115 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcmark-gfm-extensions0.29.0.gfm.3 amd64 0.29.0.gfm.3-3 [25.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 pandoc-data all 2.9.2.1-3ubuntu2 [81.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 pandoc amd64 2.9.2.1-3ubuntu2 [20.3 MB]\n",
            "Fetched 20.6 MB in 1s (14.1 MB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 4.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libcmark-gfm0.29.0.gfm.3:amd64.\n",
            "(Reading database ... 123594 files and directories currently installed.)\n",
            "Preparing to unpack .../libcmark-gfm0.29.0.gfm.3_0.29.0.gfm.3-3_amd64.deb ...\n",
            "Unpacking libcmark-gfm0.29.0.gfm.3:amd64 (0.29.0.gfm.3-3) ...\n",
            "Selecting previously unselected package libcmark-gfm-extensions0.29.0.gfm.3:amd64.\n",
            "Preparing to unpack .../libcmark-gfm-extensions0.29.0.gfm.3_0.29.0.gfm.3-3_amd64.deb ...\n",
            "Unpacking libcmark-gfm-extensions0.29.0.gfm.3:amd64 (0.29.0.gfm.3-3) ...\n",
            "Selecting previously unselected package pandoc-data.\n",
            "Preparing to unpack .../pandoc-data_2.9.2.1-3ubuntu2_all.deb ...\n",
            "Unpacking pandoc-data (2.9.2.1-3ubuntu2) ...\n",
            "Selecting previously unselected package pandoc.\n",
            "Preparing to unpack .../pandoc_2.9.2.1-3ubuntu2_amd64.deb ...\n",
            "Unpacking pandoc (2.9.2.1-3ubuntu2) ...\n",
            "Setting up libcmark-gfm0.29.0.gfm.3:amd64 (0.29.0.gfm.3-3) ...\n",
            "Setting up libcmark-gfm-extensions0.29.0.gfm.3:amd64 (0.29.0.gfm.3-3) ...\n",
            "Setting up pandoc-data (2.9.2.1-3ubuntu2) ...\n",
            "Setting up pandoc (2.9.2.1-3ubuntu2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install pandoc\n",
        "!pip install beautifulsoup4\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def create_directories():\n",
        "    input_dir = \"/content/input\"\n",
        "    output_dir = \"/content/output\"\n",
        "    txtOutput_dir = \"/content/txtOutput\"\n",
        "\n",
        "    # 創建 /content/input 目錄\n",
        "    os.makedirs(input_dir, exist_ok=True)\n",
        "    print(f\"Directory created: {input_dir}\")\n",
        "\n",
        "    # 創建 /content/output 目錄\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    print(f\"Directory created: {output_dir}\")\n",
        "    # 創建 /content/output 目錄\n",
        "    os.makedirs(txtOutput_dir, exist_ok=True)\n",
        "    print(f\"Directory created: {txtOutput_dir}\")\n",
        "\n",
        "# 執行函數創建目錄\n",
        "create_directories()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao1gyAw_lm75",
        "outputId": "91e89b08-6668-4191-9145-8af7304ad7e4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory created: /content/input\n",
            "Directory created: /content/output\n",
            "Directory created: /content/txtOutput\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "def convert_to_html(input_file, output_file):\n",
        "    # 檢查文件類型\n",
        "    file_extension = os.path.splitext(input_file)[1].lower()\n",
        "\n",
        "    if file_extension not in ['.docx', '.odt']:\n",
        "        raise ValueError(f\"Unsupported file format: {file_extension}\")\n",
        "\n",
        "    # 使用 Pandoc 將文檔轉換為 HTML\n",
        "    subprocess.run(['pandoc', '-o', output_file, input_file])\n",
        "    print(f\"Converted {input_file} to {output_file}\")\n",
        "\n",
        "# 使用範例\n",
        "# input_file = \"example.docx\"\n",
        "# output_file = \"example.html\"\n",
        "# convert_to_html(input_file, output_file)\n",
        "\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "def parse_html_and_extract_data(html_file):\n",
        "    # 打開並解析 HTML 文件\n",
        "    with open(html_file, \"r\", encoding=\"utf-8\") as file:\n",
        "        soup = BeautifulSoup(file, \"html.parser\")\n",
        "\n",
        "    # 示例：提取所有的標題和段落\n",
        "    data = {}\n",
        "    data['titles'] = [title.get_text() for title in soup.find_all(['h1', 'h2', 'h3', 'h4', 'h5', 'h6'])]\n",
        "    data['paragraphs'] = [para.get_text() for para in soup.find_all('p')]\n",
        "\n",
        "    # 提取列表\n",
        "    data['lists'] = []\n",
        "    for ul in soup.find_all('ul'):\n",
        "        items = [li.get_text() for li in ul.find_all('li')]\n",
        "        data['lists'].append(items)\n",
        "\n",
        "    # 提取表格（如果需要）\n",
        "    data['tables'] = []\n",
        "    for table in soup.find_all('table'):\n",
        "        table_data = []\n",
        "        for row in table.find_all('tr'):\n",
        "            columns = [col.get_text() for col in row.find_all(['td', 'th'])]\n",
        "            table_data.append(columns)\n",
        "        data['tables'].append(table_data)\n",
        "\n",
        "    return data\n",
        "\n",
        "# 使用範例\n",
        "# html_file = \"example.html\"\n",
        "# extracted_data = parse_html_and_extract_data(html_file)\n",
        "# print(extracted_data)\n",
        "\n",
        "#轉換為 JSON 格式：\n",
        "import json\n",
        "\n",
        "def save_data_as_json(data, output_file):\n",
        "    with open(output_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(data, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"Data saved as JSON to {output_file}\")\n",
        "\n",
        "# 使用範例\n",
        "# json_output_file = \"extracted_data.json\"\n",
        "# save_data_as_json(extracted_data, json_output_file)\n",
        "\n",
        "#轉換為 CSV 格式（僅表格數據示例）：\n",
        "import csv\n",
        "\n",
        "def save_table_data_as_csv(data, output_file):\n",
        "    with open(output_file, 'w', newline='', encoding='utf-8') as f:\n",
        "        writer = csv.writer(f)\n",
        "        for table in data['tables']:\n",
        "            writer.writerows(table)\n",
        "            writer.writerow([])  # 每個表格之間空一行\n",
        "    print(f\"Table data saved as CSV to {output_file}\")\n",
        "\n",
        "# 使用範例\n",
        "# csv_output_file = \"extracted_data.csv\"\n",
        "# save_table_data_as_csv(extracted_data, csv_output_file)\n"
      ],
      "metadata": {
        "id": "HEiVTTsvjn9x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import traceback\n",
        "\n",
        "def convert_and_extract(input_file, html_output_file, json_output_file, csv_output_file):\n",
        "    # 第一步：將文檔轉換為 HTML 格式\n",
        "    convert_to_html(input_file, html_output_file)\n",
        "\n",
        "    # 第二步：解析 HTML 並提取結構化數據\n",
        "    extracted_data = parse_html_and_extract_data(html_output_file)\n",
        "\n",
        "    # 第三步：將數據保存為 JSON 格式\n",
        "    save_data_as_json(extracted_data, json_output_file)\n",
        "\n",
        "    # 第四步：將表格數據保存為 CSV 格式\n",
        "    save_table_data_as_csv(extracted_data, csv_output_file)\n",
        "\n",
        "def convert_and_extract_with_error_handling(input_file, html_output_file, json_output_file, csv_output_file):\n",
        "    try:\n",
        "        # 執行轉換和提取\n",
        "        convert_and_extract(input_file, html_output_file, json_output_file, csv_output_file)\n",
        "        print(f\"Successfully processed {input_file}\")\n",
        "    except Exception as e:\n",
        "        # 捕獲所有異常，記錄錯誤並繼續\n",
        "        error_message = f\"Failed to process {input_file}: {str(e)}\"\n",
        "        print(error_message)\n",
        "        with open(\"error_log.txt\", \"a\", encoding=\"utf-8\") as log_file:\n",
        "            log_file.write(f\"{error_message}\\n\")\n",
        "            log_file.write(traceback.format_exc())  # 記錄完整的堆棧跟踪\n",
        "            log_file.write(\"\\n\")\n",
        "\n",
        "def batch_convert_and_extract_with_error_handling(input_folder, output_folder, summary_file):\n",
        "    summary_data = []\n",
        "\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(('.docx', '.odt')):  # 支援 DOCX 和 ODT 文件格式\n",
        "            input_file = os.path.join(input_folder, filename)\n",
        "            base_name = os.path.splitext(filename)[0]\n",
        "\n",
        "            html_output_file = os.path.join(output_folder, f\"{base_name}.html\")\n",
        "            json_output_file = os.path.join(output_folder, f\"{base_name}.json\")\n",
        "            csv_output_file = os.path.join(output_folder, f\"{base_name}.csv\")\n",
        "\n",
        "            # 對每個文件進行轉換和提取，並添加錯誤處理\n",
        "            convert_and_extract_with_error_handling(input_file, html_output_file, json_output_file, csv_output_file)\n",
        "\n",
        "            # 如果 JSON 文件成功生成，則將其匯總\n",
        "            if os.path.exists(json_output_file):\n",
        "                with open(json_output_file, 'r', encoding='utf-8') as f:\n",
        "                    file_data = json.load(f)\n",
        "                    summary_data.append({base_name: file_data})\n",
        "\n",
        "    # 將匯總結果保存為 JSON 文件\n",
        "    with open(summary_file, 'w', encoding='utf-8') as f:\n",
        "        json.dump(summary_data, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"Summary saved to {summary_file}\")\n",
        "\n",
        "# 使用範例\n",
        "input_folder = \"/content/input\"\n",
        "output_folder = \"/content/output\"\n",
        "summary_file = \"/content/output/summary.json\"\n",
        "\n",
        "batch_convert_and_extract_with_error_handling(input_folder, output_folder, summary_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqaTpQIZj_2g",
        "outputId": "de2de88f-1476-4eec-8689-b3b15580ee5b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted /content/input/附件1-113年第1次資料開放工作小組會議紀錄 (1).odt to /content/output/附件1-113年第1次資料開放工作小組會議紀錄 (1).html\n",
            "Data saved as JSON to /content/output/附件1-113年第1次資料開放工作小組會議紀錄 (1).json\n",
            "Table data saved as CSV to /content/output/附件1-113年第1次資料開放工作小組會議紀錄 (1).csv\n",
            "Successfully processed /content/input/附件1-113年第1次資料開放工作小組會議紀錄 (1).odt\n",
            "Converted /content/input/113年第2次資料開放工作小組會議紀錄.odt to /content/output/113年第2次資料開放工作小組會議紀錄.html\n",
            "Data saved as JSON to /content/output/113年第2次資料開放工作小組會議紀錄.json\n",
            "Table data saved as CSV to /content/output/113年第2次資料開放工作小組會議紀錄.csv\n",
            "Successfully processed /content/input/113年第2次資料開放工作小組會議紀錄.odt\n",
            "Converted /content/input/附件1-1111006業務會議紀錄.odt to /content/output/附件1-1111006業務會議紀錄.html\n",
            "Data saved as JSON to /content/output/附件1-1111006業務會議紀錄.json\n",
            "Table data saved as CSV to /content/output/附件1-1111006業務會議紀錄.csv\n",
            "Successfully processed /content/input/附件1-1111006業務會議紀錄.odt\n",
            "Summary saved to /content/output/summary.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "def json_to_txt(json_file, output_file):\n",
        "    try:\n",
        "        # 讀取 JSON 文件\n",
        "        with open(json_file, 'r', encoding='utf-8') as f:\n",
        "            data = json.load(f)\n",
        "\n",
        "        # 開始寫入 TXT 文件\n",
        "        with open(output_file, 'w', encoding='utf-8') as f:\n",
        "            # 寫入標題\n",
        "            if 'titles' in data:\n",
        "                for title in data['titles']:\n",
        "                    f.write(f\"# {title}\\n\\n\")  # 使用 # 表示標題\n",
        "\n",
        "            # 寫入段落\n",
        "            if 'paragraphs' in data:\n",
        "                for paragraph in data['paragraphs']:\n",
        "                    f.write(f\"{paragraph}\\n\\n\")  # 每段後加兩個換行\n",
        "\n",
        "            # 寫入列表\n",
        "            if 'lists' in data:\n",
        "                for lst in data['lists']:\n",
        "                    for item in lst:\n",
        "                        f.write(f\"- {item}\\n\")  # 使用 - 表示列表項\n",
        "                    f.write(\"\\n\")  # 列表之間加一個換行\n",
        "\n",
        "            # 寫入表格\n",
        "            if 'tables' in data:\n",
        "                for table in data['tables']:\n",
        "                    for row in table:\n",
        "                        f.write(\" | \".join(row) + \"\\n\")  # 使用 | 分隔表格列\n",
        "                    f.write(\"\\n\")  # 表格之間加一個換行\n",
        "\n",
        "        print(f\"Converted {json_file} to {output_file}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Failed to process {json_file}: {e}\")\n",
        "\n",
        "# 使用範例\n",
        "# json_file = \"extracted_data.json\"\n",
        "# output_file = \"output_data.txt\"\n",
        "# json_to_txt(json_file, output_file)\n",
        "\n",
        "def batch_json_to_txt(input_folder, output_folder):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith('.json'):\n",
        "            json_file = os.path.join(input_folder, filename)\n",
        "            output_file = os.path.join(output_folder, f\"{os.path.splitext(filename)[0]}.txt\")\n",
        "            json_to_txt(json_file, output_file)\n",
        "\n",
        "# 使用範例\n",
        "input_folder = \"/content/output\"\n",
        "output_folder = \"/content/txtOutput\"\n",
        "\n",
        "batch_json_to_txt(input_folder, output_folder)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9cVZvglwiej",
        "outputId": "2f4f11b2-7949-423f-b164-b72e5b3d46dd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted /content/output/附件1-1111006業務會議紀錄.json to /content/txtOutput/附件1-1111006業務會議紀錄.txt\n",
            "Converted /content/output/附件1-113年第1次資料開放工作小組會議紀錄 (1).json to /content/txtOutput/附件1-113年第1次資料開放工作小組會議紀錄 (1).txt\n",
            "Converted /content/output/113年第2次資料開放工作小組會議紀錄.json to /content/txtOutput/113年第2次資料開放工作小組會議紀錄.txt\n",
            "Converted /content/output/summary.json to /content/txtOutput/summary.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "def zip_output_directory():\n",
        "    output_dir = \"/content/output\"\n",
        "    zip_file_path = \"/content/output_archive.zip\"\n",
        "\n",
        "    # 確保 output 目錄存在\n",
        "    if os.path.exists(output_dir):\n",
        "        # 使用 shutil.make_archive 創建 ZIP 文件\n",
        "        shutil.make_archive(zip_file_path.replace('.zip', ''), 'zip', output_dir)\n",
        "        print(f\"Directory {output_dir} has been zipped into {zip_file_path}\")\n",
        "    else:\n",
        "        print(f\"Directory {output_dir} does not exist\")\n",
        "\n",
        "# 執行打包\n",
        "zip_output_directory()\n"
      ],
      "metadata": {
        "id": "ZUGoxQo9nMHR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}