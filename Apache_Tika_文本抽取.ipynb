{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdoA40/m20asy0gmLoxqg2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iim0663418/LLMDataOptimization/blob/main/Apache_Tika_%E6%96%87%E6%9C%AC%E6%8A%BD%E5%8F%96.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Apache Tika\n",
        "\n",
        "Apache Tika 是一個開源的內容分析工具，它可以從多種文檔格式中提取文本和元數據。雖然它主要用於內容分析，但也可以用來進行文件格式轉換。"
      ],
      "metadata": {
        "id": "jpkwgbtdcfit"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUFRuhOgcbDH",
        "outputId": "5a0abce9-2de8-4411-bf11-e6725243163c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tika\n",
            "  Downloading tika-2.6.0.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tika) (71.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from tika) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->tika) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->tika) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->tika) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->tika) (2024.7.4)\n",
            "Building wheels for collected packages: tika\n",
            "  Building wheel for tika (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tika: filename=tika-2.6.0-py3-none-any.whl size=32623 sha256=664c158cbb4119ca3e78c4c9bb0cf767b776cf9fd93a261def80e9ab0f45674a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/71/c7/b757709531121b1700cffda5b6b0d4aad095fb507ec84316d0\n",
            "Successfully built tika\n",
            "Installing collected packages: tika\n",
            "Successfully installed tika-2.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install tika"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def create_directories():\n",
        "    input_dir = \"/content/input\"\n",
        "    output_dir = \"/content/output\"\n",
        "\n",
        "    # 創建 /content/input 目錄\n",
        "    os.makedirs(input_dir, exist_ok=True)\n",
        "    print(f\"Directory created: {input_dir}\")\n",
        "\n",
        "    # 創建 /content/output 目錄\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    print(f\"Directory created: {output_dir}\")\n",
        "\n",
        "# 執行函數創建目錄\n",
        "create_directories()\n"
      ],
      "metadata": {
        "id": "slORZm30es9z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from multiprocessing import Pool, TimeoutError\n",
        "from tika import parser\n",
        "\n",
        "# 記錄錯誤日誌\n",
        "def log_error(file_path, error):\n",
        "    with open(\"error_log.txt\", \"a\", encoding=\"utf-8\") as log_file:\n",
        "        log_file.write(f\"Error processing {file_path}: {error}\\n\")\n",
        "\n",
        "import re\n",
        "\n",
        "def remove_control_characters(text):\n",
        "    # 移除非打印字符\n",
        "    text = re.sub(r'[\\x00-\\x1F\\x7F]', '', text)\n",
        "    return text\n",
        "\n",
        "def remove_duplicate_punctuation(text):\n",
        "    text = re.sub(r'([.?!,])\\1+', r'\\1', text)  # 替換重複的標點\n",
        "    return text\n",
        "\n",
        "def remove_unwanted_tags(text):\n",
        "    # 移除特定的標記，如頁碼（假設格式為 \"Page X of Y\"）\n",
        "    text = re.sub(r'Page \\d+ of \\d+', '', text)\n",
        "    # 移除其他特定格式（例如 \"[註腳1]\" 等）\n",
        "    text = re.sub(r'\\[\\w+\\d+\\]', '', text)\n",
        "    return text\n",
        "\n",
        "def rejoin_broken_paragraphs(text):\n",
        "    # 假設段落之間有兩個換行符，段落內部只有一個換行符\n",
        "    text = re.sub(r'(?<!\\n)\\n(?!\\n)', ' ', text)\n",
        "    return text\n",
        "\n",
        "def normalize_whitespace(text):\n",
        "    text = re.sub(r'\\s+', ' ', text)  # 多個空格轉換為一個\n",
        "    text = re.sub(r'\\s([?.!,;:])', r'\\1', text)  # 去掉標點符號前的空格\n",
        "    return text\n",
        "\n",
        "def fix_encoding_issues(text):\n",
        "    # 例如，將常見的編碼問題字符替換為正確字符\n",
        "    text = text.replace('â€™', \"'\").replace('â€œ', '\"').replace('â€', '\"')\n",
        "    return text\n",
        "\n",
        "def remove_urls_and_emails(text):\n",
        "    # 移除 URL\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    # 移除 Email 地址\n",
        "    text = re.sub(r'\\S+@\\S+', '', text)\n",
        "    return text\n",
        "\n",
        "def handle_bullet_points(text):\n",
        "    # 將項目符號（如 \"*\", \"-\"）前的空格進行規範化\n",
        "    text = re.sub(r'\\n\\s*([*-])', r'\\n\\1', text)\n",
        "    return text\n",
        "\n",
        "def comprehensive_text_cleaning(text):\n",
        "    text = remove_control_characters(text)\n",
        "    text = remove_duplicate_punctuation(text)\n",
        "    text = normalize_whitespace(text)\n",
        "    text = remove_unwanted_tags(text)\n",
        "    text = rejoin_broken_paragraphs(text)\n",
        "    text = handle_bullet_points(text)\n",
        "    text = fix_encoding_issues(text)\n",
        "    text = remove_urls_and_emails(text)\n",
        "    return text\n",
        "\n",
        "# 提取文本並保存的函數\n",
        "def extract_text_and_save(args):\n",
        "    input_path, output_folder = args\n",
        "    try:\n",
        "        file_base = os.path.splitext(os.path.basename(input_path))[0]\n",
        "        output_path = os.path.join(output_folder, f\"{file_base}.txt\")\n",
        "\n",
        "        # 使用 Tika 解析文件並提取文本\n",
        "        text_content = parser.from_file(input_path)[\"content\"]\n",
        "\n",
        "        # 綜合文本清理\n",
        "        cleaned_text = comprehensive_text_cleaning(text_content)\n",
        "\n",
        "        # 保存清理後的文本\n",
        "        with open(output_path, \"w\", encoding=\"utf-8\") as output_file:\n",
        "            output_file.write(cleaned_text or \"\")\n",
        "        print(f\"Processed {input_path} -> {output_path}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {input_path}: {e}\")\n",
        "        log_error(input_path, e)\n",
        "\n",
        "# 批次處理文件的函數\n",
        "def process_batch(file_batch, output_folder, timeout):\n",
        "    for file_path in file_batch:\n",
        "        try:\n",
        "            extract_text_and_save_with_retry((file_path, output_folder), timeout)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {file_path}: {e}\")\n",
        "            log_error(file_path, e)\n",
        "\n",
        "# 將文件分成批次\n",
        "def chunk_files(file_list, chunk_size):\n",
        "    for i in range(0, len(file_list), chunk_size):\n",
        "        yield file_list[i:i + chunk_size]\n",
        "\n",
        "# 改進的批次處理函數\n",
        "def batch_process_with_chunks(input_folder, output_folder, num_workers=4, timeout=300, chunk_size=100):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    file_list = [os.path.join(input_folder, filename)\n",
        "                 for filename in os.listdir(input_folder)\n",
        "                 if os.path.isfile(os.path.join(input_folder, filename))]\n",
        "\n",
        "    file_chunks = list(chunk_files(file_list, chunk_size))\n",
        "\n",
        "    with Pool(processes=num_workers) as pool:\n",
        "        for file_chunk in file_chunks:\n",
        "            pool.apply_async(process_batch, args=(file_chunk, output_folder, timeout))\n",
        "\n",
        "        pool.close()\n",
        "        pool.join()\n",
        "\n",
        "# 帶重試的提取文本並保存函數\n",
        "def extract_text_and_save_with_retry(args, retries=3):\n",
        "    input_path, output_folder = args\n",
        "    for attempt in range(retries):\n",
        "        try:\n",
        "            extract_text_and_save(args)\n",
        "            return\n",
        "        except Exception as e:\n",
        "            print(f\"Attempt {attempt + 1} failed for {input_path}: {e}\")\n",
        "            if attempt + 1 == retries:\n",
        "                log_error(input_path, e)\n",
        "\n",
        "# 批次處理資料夾\n",
        "def batch_process_with_timeout(input_folder, output_folder, num_workers=4, timeout=300):\n",
        "    if not os.path.exists(output_folder):\n",
        "        os.makedirs(output_folder)\n",
        "\n",
        "    file_list = [(os.path.join(input_folder, filename), output_folder)\n",
        "                 for filename in os.listdir(input_folder)\n",
        "                 if os.path.isfile(os.path.join(input_folder, filename))]\n",
        "\n",
        "    with Pool(processes=num_workers) as pool:\n",
        "        for file_args in file_list:\n",
        "            try:\n",
        "                pool.apply_async(extract_text_and_save_with_retry, args=(file_args,)).get(timeout=timeout)\n",
        "            except TimeoutError:\n",
        "                print(f\"Timeout processing {file_args[0]}\")\n",
        "                log_error(file_args[0], \"TimeoutError\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing {file_args[0]}: {e}\")\n",
        "                log_error(file_args[0], e)\n",
        "\n",
        "# 使用範例\n",
        "input_folder = \"/content/input\"\n",
        "output_folder = \"/content/output\"\n",
        "num_workers = 4  # 設置使用的進程數\n",
        "timeout = 300  # 設置每個文件的處理超時時間（秒）\n",
        "chunk_size = 100  # 每批次處理的文件數量\n",
        "\n",
        "batch_process_with_chunks(input_folder, output_folder, num_workers, timeout, chunk_size)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFoCt9f4ckew",
        "outputId": "cef0afbe-ed52-4cfd-ff1a-c97f558b4149"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed /content/input/附件1-113年第1次資料開放工作小組會議紀錄 (1).odt -> /content/output/附件1-113年第1次資料開放工作小組會議紀錄 (1).txt\n",
            "Processed /content/input/113年第2次資料開放工作小組會議紀錄.odt -> /content/output/113年第2次資料開放工作小組會議紀錄.txt\n",
            "Processed /content/input/附件1-1111006業務會議紀錄.odt -> /content/output/附件1-1111006業務會議紀錄.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "def zip_output_directory():\n",
        "    output_dir = \"/content/output\"\n",
        "    zip_file_path = \"/content/output_archive.zip\"\n",
        "\n",
        "    # 確保 output 目錄存在\n",
        "    if os.path.exists(output_dir):\n",
        "        # 使用 shutil.make_archive 創建 ZIP 文件\n",
        "        shutil.make_archive(zip_file_path.replace('.zip', ''), 'zip', output_dir)\n",
        "        print(f\"Directory {output_dir} has been zipped into {zip_file_path}\")\n",
        "    else:\n",
        "        print(f\"Directory {output_dir} does not exist\")\n",
        "\n",
        "# 執行打包\n",
        "zip_output_directory()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0y1fs0_hcwu",
        "outputId": "a84c8688-e997-4ba3-cc92-d109a5d139d3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory /content/output has been zipped into /content/output_archive.zip\n"
          ]
        }
      ]
    }
  ]
}